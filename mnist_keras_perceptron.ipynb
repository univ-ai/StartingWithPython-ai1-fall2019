{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mnist-keras-perceptron.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahuldave/StartingWithPython-ai1-fall2019/blob/master/mnist_keras_perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rrbVKm5n6E3",
        "colab_type": "code",
        "outputId": "fc3b3113-0f02-4a99-9712-0eec7972aad1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# taken from lukas/ml-class\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, Dropout\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import Callback\n",
        "import json\n",
        "\n",
        "# from wandb.keras import WandbCallback\n",
        "# import wandb\n",
        "\n",
        "# run = wandb.init()\n",
        "# config = run.config\n",
        "\n",
        "class Config:\n",
        "  pass\n",
        "\n",
        "config = Config()\n",
        "config.optimizer = \"adam\"\n",
        "config.epochs = 30\n",
        "config.hidden_nodes = 30\n",
        "\n",
        "# load data\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "img_width = X_train.shape[1]\n",
        "img_height = X_train.shape[2]\n",
        "print(X_train.shape, y_train.shape)\n",
        "#X_train = X_train.astype('float32')\n",
        "#X_train /= 255.\n",
        "#X_test = X_test.astype('float32')\n",
        "#X_test /= 255.\n",
        "\n",
        "# Normalize, change learning rate, play with layer size, batchsize\n",
        "\n",
        "# one hot encode outputs\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "labels = range(10)\n",
        "\n",
        "num_classes = y_train.shape[1]\n",
        "\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(img_width, img_height)))\n",
        "model.add(Dense(config.hidden_nodes, activation='relu'))\n",
        "model.add(Dense(config.hidden_nodes, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer=config.optimizer,\n",
        "              metrics=['accuracy'])\n",
        "model.summary()\n",
        "# Fit the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test),\n",
        "          epochs=config.epochs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n",
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_3 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 30)                23550     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 30)                930       \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 10)                310       \n",
            "=================================================================\n",
            "Total params: 24,790\n",
            "Trainable params: 24,790\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/30\n",
            "60000/60000 [==============================] - 10s 164us/step - loss: 8.1156 - acc: 0.4876 - val_loss: 7.4235 - val_acc: 0.5358\n",
            "Epoch 2/30\n",
            "60000/60000 [==============================] - 10s 161us/step - loss: 7.5295 - acc: 0.5295 - val_loss: 7.4544 - val_acc: 0.5340\n",
            "Epoch 3/30\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 7.3746 - acc: 0.5400 - val_loss: 7.3362 - val_acc: 0.5428\n",
            "Epoch 4/30\n",
            "60000/60000 [==============================] - 10s 161us/step - loss: 7.3471 - acc: 0.5424 - val_loss: 7.4127 - val_acc: 0.5378\n",
            "Epoch 5/30\n",
            "60000/60000 [==============================] - 10s 161us/step - loss: 7.3119 - acc: 0.5447 - val_loss: 7.3382 - val_acc: 0.5438\n",
            "Epoch 6/30\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 7.2799 - acc: 0.5469 - val_loss: 7.3687 - val_acc: 0.5412\n",
            "Epoch 7/30\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 7.2363 - acc: 0.5498 - val_loss: 7.2577 - val_acc: 0.5491\n",
            "Epoch 8/30\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 7.1731 - acc: 0.5539 - val_loss: 7.3855 - val_acc: 0.5409\n",
            "Epoch 9/30\n",
            "60000/60000 [==============================] - 9s 158us/step - loss: 7.2618 - acc: 0.5486 - val_loss: 7.1870 - val_acc: 0.5535\n",
            "Epoch 10/30\n",
            "60000/60000 [==============================] - 9s 157us/step - loss: 7.2290 - acc: 0.5507 - val_loss: 7.1894 - val_acc: 0.5528\n",
            "Epoch 11/30\n",
            "60000/60000 [==============================] - 10s 158us/step - loss: 7.2104 - acc: 0.5519 - val_loss: 7.1606 - val_acc: 0.5549\n",
            "Epoch 12/30\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 7.1716 - acc: 0.5544 - val_loss: 7.4159 - val_acc: 0.5391\n",
            "Epoch 13/30\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 7.1579 - acc: 0.5552 - val_loss: 7.1898 - val_acc: 0.5531\n",
            "Epoch 14/30\n",
            "60000/60000 [==============================] - 10s 161us/step - loss: 7.2024 - acc: 0.5525 - val_loss: 7.1369 - val_acc: 0.5566\n",
            "Epoch 15/30\n",
            "60000/60000 [==============================] - 10s 162us/step - loss: 7.1078 - acc: 0.5584 - val_loss: 7.1295 - val_acc: 0.5573\n",
            "Epoch 16/30\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 7.1577 - acc: 0.5553 - val_loss: 7.4362 - val_acc: 0.5381\n",
            "Epoch 17/30\n",
            "60000/60000 [==============================] - 10s 160us/step - loss: 7.1505 - acc: 0.5559 - val_loss: 7.3943 - val_acc: 0.5405\n",
            "Epoch 18/30\n",
            "60000/60000 [==============================] - 9s 157us/step - loss: 7.1486 - acc: 0.5559 - val_loss: 7.1699 - val_acc: 0.5545\n",
            "Epoch 19/30\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 7.1455 - acc: 0.5563 - val_loss: 7.1135 - val_acc: 0.5581\n",
            "Epoch 20/30\n",
            "60000/60000 [==============================] - 9s 157us/step - loss: 7.1796 - acc: 0.5541 - val_loss: 7.1265 - val_acc: 0.5577\n",
            "Epoch 21/30\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 7.1377 - acc: 0.5567 - val_loss: 7.0869 - val_acc: 0.5601\n",
            "Epoch 22/30\n",
            "60000/60000 [==============================] - 9s 157us/step - loss: 7.1339 - acc: 0.5570 - val_loss: 7.3836 - val_acc: 0.5414\n",
            "Epoch 23/30\n",
            "60000/60000 [==============================] - 9s 158us/step - loss: 7.0259 - acc: 0.5636 - val_loss: 6.4336 - val_acc: 0.6001\n",
            "Epoch 24/30\n",
            "60000/60000 [==============================] - 9s 158us/step - loss: 5.9435 - acc: 0.6306 - val_loss: 5.9936 - val_acc: 0.6273\n",
            "Epoch 25/30\n",
            "60000/60000 [==============================] - 9s 158us/step - loss: 5.7927 - acc: 0.6400 - val_loss: 5.8227 - val_acc: 0.6381\n",
            "Epoch 26/30\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 5.7774 - acc: 0.6411 - val_loss: 5.7659 - val_acc: 0.6416\n",
            "Epoch 27/30\n",
            "60000/60000 [==============================] - 10s 160us/step - loss: 5.6935 - acc: 0.6463 - val_loss: 5.7679 - val_acc: 0.6417\n",
            "Epoch 28/30\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 5.6663 - acc: 0.6480 - val_loss: 5.6881 - val_acc: 0.6467\n",
            "Epoch 29/30\n",
            "60000/60000 [==============================] - 10s 158us/step - loss: 5.6549 - acc: 0.6488 - val_loss: 5.7310 - val_acc: 0.6440\n",
            "Epoch 30/30\n",
            "60000/60000 [==============================] - 10s 159us/step - loss: 5.6750 - acc: 0.6475 - val_loss: 5.7962 - val_acc: 0.6398\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc9f566af98>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    }
  ]
}